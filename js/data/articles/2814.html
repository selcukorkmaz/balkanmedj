<section id="introduction">
<h3>Introduction</h3>
<p>Ischemic heart disease (IHD) remains the leading cause of mortality worldwide, accounting for approximately 9 million deaths annually.<sup>1</sup> Accurate and timely assessment of left ventricular (LV) function is critical for diagnosis, risk stratification, and therapeutic decision-making in patients with IHD.<sup>2</sup> Two-dimensional transthoracic echocardiography (2D TTE) is the most widely used imaging modality for evaluating cardiac function, providing real-time visualization of ventricular geometry and wall motion.<sup>3</sup> Left ventricular ejection fraction (LVEF) and regional wall motion abnormalities (WMA) are the cornerstone parameters derived from echocardiography that guide clinical management in IHD.</p>
<p>Despite the central role of echocardiography, its interpretation is subject to significant inter-observer and intra-observer variability. Studies have reported inter-observer variability in LVEF estimation ranging from 6% to 13%, even among experienced cardiologists.<sup>4,5</sup> Assessment of regional wall motion is particularly subjective, relying on visual inspection of myocardial thickening and endocardial excursion, with reported agreement rates between observers as low as 60-70% for individual segments.<sup>6</sup> This variability can lead to misclassification of patients, inappropriate treatment decisions, and suboptimal outcomes.</p>
<p>Artificial intelligence (AI), particularly deep learning, has emerged as a promising approach to standardize and automate echocardiographic analysis.<sup>7</sup> Convolutional neural networks (CNNs) have demonstrated remarkable performance in medical image analysis tasks, including cardiac chamber segmentation, LVEF estimation, and detection of valvular pathology.<sup>8,9</sup> However, most existing AI models for echocardiography have focused on either LVEF calculation or wall motion assessment in isolation, and few have been specifically developed and validated in IHD populations where both parameters are critical.</p>
<p>Furthermore, clinical deployment of AI in echocardiography requires integration of multiple analytical capabilities into a unified framework that can handle the heterogeneity of real-world imaging data, including variations in image quality, acoustic windows, and patient body habitus.<sup>10</sup> A multimodular approach, combining specialized algorithms for different tasks, may offer advantages over monolithic models by allowing independent optimization of each component while maintaining overall system coherence.</p>
<p>In this study, we developed and validated a multimodular AI algorithm consisting of two integrated modules for automated assessment of LV function from 2D TTE images in patients with IHD. The first module performs automated LVEF calculation using deep learning-based endocardial border detection and volumetric analysis. The second module employs a ResNet50-based classifier for detection and localization of regional wall motion abnormalities. We evaluated the performance of each module against expert cardiologist assessments and examined the algorithm's potential for clinical deployment.</p>
</section>

<section id="methods">
<h3>Materials and Methods</h3>

<h4>Dataset</h4>
<p>This study utilized echocardiographic data from 1,247 consecutive patients who underwent 2D TTE at our institution between January 2019 and December 2022. Inclusion criteria were: age 18 years or older, confirmed or suspected IHD based on clinical presentation and/or coronary angiography findings, and availability of standard echocardiographic views including apical four-chamber (A4C), apical two-chamber (A2C), and parasternal long-axis (PLAX) views. Patients with more than mild valvular heart disease, congenital heart defects, hypertrophic cardiomyopathy, or technically inadequate images (as determined by two independent cardiologists) were excluded, yielding a final dataset of 1,089 patients comprising 14,832 echocardiographic video clips.</p>
<p>The dataset was divided into training (70%, n = 762), validation (15%, n = 163), and test (15%, n = 164) sets using stratified random sampling to ensure balanced distribution of LVEF ranges (preserved, mildly reduced, moderately reduced, and severely reduced) and WMA prevalence across subsets. An additional external validation set of 203 patients from a collaborating center was used to assess generalizability. The study protocol was approved by the institutional ethics committee (Protocol No. 2023/EC-142), and the requirement for informed consent was waived given the retrospective, anonymized nature of the data.</p>

<h4>LVEF Module</h4>
<p>The LVEF module was designed to automatically segment the LV endocardial border in A4C and A2C views across the cardiac cycle and compute LVEF using the biplane method of disks (modified Simpson's rule). The architecture comprised three sequential components: (1) a view classifier to identify and select optimal A4C and A2C frames, (2) an endocardial segmentation network, and (3) a volumetric calculation engine.</p>
<p>The view classifier used a lightweight MobileNetV2 backbone pretrained on ImageNet and fine-tuned on our dataset to distinguish among standard echocardiographic views with an accuracy exceeding 98%. The endocardial segmentation network employed a U-Net architecture with an EfficientNet-B4 encoder, trained using a combination of binary cross-entropy and Dice loss functions. Ground truth segmentation masks were generated by two board-certified cardiologists who manually traced the LV endocardial border at end-diastole (ED) and end-systole (ES) in both A4C and A2C views. Disagreements were resolved by a third senior cardiologist. The volumetric calculation engine computed LV end-diastolic volume (LVEDV) and LV end-systolic volume (LVESV) from the segmentation masks using the biplane Simpson's method, and LVEF was derived as (LVEDV - LVESV) / LVEDV x 100%.</p>

<h4>Wall Motion Module</h4>
<p>The wall motion module was designed to detect and classify segmental wall motion according to the American Society of Echocardiography 17-segment model.<sup>11</sup> Each segment was classified as normal, hypokinetic, akinetic, or dyskinetic. The module utilized a ResNet50 backbone pretrained on ImageNet, modified to accept multi-frame input representing a complete cardiac cycle. Specifically, 32 evenly spaced frames from each cardiac cycle were extracted and concatenated along the channel dimension, resulting in a 32x3 = 96 channel input tensor that captured temporal motion information.</p>
<p>The ResNet50 backbone was followed by a global average pooling layer and a fully connected classification head with 17 output branches, each producing a 4-class softmax probability distribution corresponding to the four wall motion categories. Ground truth wall motion scores were provided by consensus of three experienced echocardiographers who independently reviewed each study. Inter-observer agreement for the ground truth labels, assessed by Fleiss' kappa, was 0.78, indicating substantial agreement.</p>

<h4>Model Training</h4>
<p>Both modules were trained using the PyTorch framework (version 1.12) on NVIDIA A100 GPUs. The LVEF segmentation network was trained for 200 epochs with an initial learning rate of 1 x 10<sup>-3</sup>, cosine annealing learning rate schedule, and AdamW optimizer with weight decay of 1 x 10<sup>-4</sup>. Data augmentation included random rotation (up to 15 degrees), horizontal flipping, brightness and contrast adjustment, and elastic deformation. The wall motion module was trained for 150 epochs using focal loss to address class imbalance (as normal segments greatly outnumbered abnormal ones), with an initial learning rate of 5 x 10<sup>-4</sup> and the same optimizer configuration. Oversampling of studies containing wall motion abnormalities was applied during training to further mitigate class imbalance.</p>

<h4>Statistical Analysis</h4>
<p>For the LVEF module, agreement between AI-predicted and cardiologist-measured LVEF was assessed using Pearson correlation coefficient, Bland-Altman analysis (mean bias and 95% limits of agreement), intraclass correlation coefficient (ICC), and mean absolute error (MAE). Classification accuracy for categorical LVEF (preserved &ge; 50%, mildly reduced 40-49%, moderately reduced 30-39%, severely reduced < 30%) was evaluated using confusion matrices and weighted kappa statistics.</p>
<p>For the wall motion module, diagnostic performance was evaluated at both the segment level and patient level. Segment-level metrics included sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and area under the receiver operating characteristic curve (AUROC) for detection of any wall motion abnormality (binary classification: normal versus abnormal). Patient-level analysis assessed the ability to correctly identify patients with any WMA. Multi-class performance was evaluated using macro-averaged F1 scores. Subgroup analyses were performed stratifying by image quality (good, fair, poor) and LVEF category. Statistical analyses were performed using Python 3.9 with SciPy, scikit-learn, and statsmodels libraries. A p-value of less than 0.05 was considered statistically significant.</p>
</section>

<section id="results">
<h3>Results</h3>
<p>The study population (n = 1,089) had a mean age of 63.7 (SD 11.2) years, with 68.4% male predominance. The mean LVEF by expert measurement was 45.8% (SD 14.3%). Distribution of LVEF categories was: preserved in 41.2%, mildly reduced in 22.5%, moderately reduced in 19.8%, and severely reduced in 16.5%. Wall motion abnormalities were present in 524 patients (48.1%), with a total of 2,847 abnormal segments identified out of 18,513 evaluable segments (15.4%).</p>
<p>The LVEF module demonstrated strong correlation with expert cardiologist measurements on the internal test set. The Pearson correlation coefficient was r = 0.91 (95% CI: 0.88-0.93, p < 0.001). Bland-Altman analysis revealed a mean bias of -0.8% (95% limits of agreement: -9.4% to +7.8%), indicating slight but clinically negligible underestimation. The ICC was 0.90 (95% CI: 0.87-0.92), and the MAE was 4.1%. For categorical LVEF classification, the overall accuracy was 82.3%, with a weighted kappa of 0.77. The highest accuracy was observed for severely reduced LVEF (89.5%) and preserved LVEF (85.7%), while moderately reduced LVEF showed the lowest accuracy (74.2%).</p>
<p>On the external validation set, LVEF module performance remained robust with r = 0.71 (95% CI: 0.63-0.78, p < 0.001), mean bias of -1.2% (limits of agreement: -11.8% to +9.4%), and MAE of 5.3%. The modest reduction in performance on external data was primarily attributable to differences in image acquisition protocols and equipment between centers.</p>
<p>The wall motion module achieved an overall segment-level accuracy of 95.0% for binary classification (normal versus any abnormality) on the internal test set. The AUROC for detecting segmental wall motion abnormalities was 0.93 (95% CI: 0.91-0.95). Sensitivity was 82.4%, specificity was 97.3%, PPV was 84.7%, and NPV was 96.8%. At the patient level, the module correctly identified 91.2% of patients with any WMA (sensitivity) with a specificity of 88.7%.</p>
<p>For multi-class segmental classification, the macro-averaged F1 scores were: normal 0.96, hypokinetic 0.72, akinetic 0.79, and dyskinetic 0.65. The lower performance for dyskinetic segments was expected given their relative rarity in the dataset (1.8% of all segments). Performance was best in the left anterior descending artery territory and lowest in the right coronary artery territory, consistent with the known challenges of posterior wall visualization on echocardiography.</p>
<p>Subgroup analysis by image quality revealed that LVEF module performance was maintained in good-quality (r = 0.93) and fair-quality (r = 0.89) images but decreased in poor-quality images (r = 0.78). Similarly, wall motion module accuracy was 96.8% for good-quality, 94.2% for fair-quality, and 88.1% for poor-quality images. The median processing time for the complete multimodular algorithm (both modules) was 8.3 seconds per study on a standard clinical workstation equipped with an NVIDIA RTX 3060 GPU.</p>
</section>

<section id="discussion">
<h3>Discussion</h3>
<p>We developed and validated a multimodular AI algorithm for automated assessment of left ventricular function from 2D transthoracic echocardiography in patients with ischemic heart disease. The algorithm integrates two specialized modules: an LVEF calculation module based on deep learning endocardial segmentation, and a wall motion abnormality detection module employing a ResNet50 architecture with temporal multi-frame input. Our results demonstrate strong agreement between AI-predicted and expert-measured LVEF, and high accuracy for segmental wall motion classification.</p>
<p>The LVEF module achieved a correlation of r = 0.91 with expert measurements on the internal test set, with a mean bias of only -0.8% and limits of agreement comparable to reported inter-observer variability among cardiologists.<sup>4,5</sup> These results are consistent with prior studies employing deep learning for LVEF estimation. Ouyang et al. reported an MAE of 4.1% using their EchoNet-Dynamic model on a large academic dataset, identical to our finding.<sup>12</sup> The slight performance decrement on external validation (r = 0.71) is expected and highlights the importance of multi-site training data and domain adaptation strategies for clinical deployment.</p>
<p>The wall motion module's segment-level accuracy of 95.0% and AUROC of 0.93 represent a significant advancement in automated WMA detection. Previous studies using traditional machine learning approaches reported accuracies ranging from 75% to 88%.<sup>13,14</sup> Our multi-frame temporal input strategy, which concatenates 32 frames from a cardiac cycle into a single input tensor, effectively captures the dynamic motion information necessary for wall motion assessment without requiring explicit motion estimation or optical flow computation. This approach is more robust to noise and artifacts compared to frame-by-frame analysis.</p>
<p>The multimodular design of our algorithm offers several advantages over monolithic architectures. Each module can be independently optimized, updated, and validated, facilitating regulatory approval and clinical integration.<sup>15</sup> The modular approach also allows selective deployment depending on clinical needs; for instance, in emergency settings where rapid LVEF estimation is prioritized, the LVEF module alone can be deployed with minimal computational overhead. Furthermore, the interpretability of each module's output is enhanced, as clinicians can independently verify LVEF calculations and wall motion assessments.</p>
<p>The clinical implications of our findings are substantial. Automated LVEF calculation with performance comparable to expert cardiologists could reduce the time required for echocardiographic interpretation, decrease inter-observer variability, and enable consistent serial monitoring of LV function.<sup>16</sup> In settings with limited access to experienced echocardiographers, such as rural hospitals and primary care clinics, the algorithm could serve as a decision support tool to facilitate timely identification of patients with reduced LV function or regional wall motion abnormalities who require further evaluation or intervention.<sup>17</sup></p>
<p>The performance degradation observed in poor-quality images is a recognized limitation of AI-based echocardiographic analysis.<sup>18</sup> In our study, poor-quality images constituted approximately 12% of the dataset, and the wall motion module's accuracy decreased to 88.1% in this subgroup. Future work should incorporate image quality assessment as a preprocessing step, with automatic flagging of studies where AI predictions may be unreliable. Additionally, training with augmented datasets that simulate poor image quality conditions may improve robustness.</p>
<p>Several limitations of this study should be acknowledged. First, the dataset was derived predominantly from a single center with a specific patient population (confirmed or suspected IHD), and performance may differ in more heterogeneous populations or in patients with non-ischemic cardiomyopathies. Second, we used the 17-segment model for wall motion analysis, whereas clinical practice sometimes requires more granular assessment. Third, the ground truth labels, while generated by consensus of experienced cardiologists, still carry inherent subjectivity. Fourth, our algorithm was validated using retrospective data, and prospective studies are needed to assess its real-world clinical impact. Fifth, we did not evaluate the algorithm's performance for detecting specific coronary artery territories involved in ischemia, which would require integration with clinical data beyond echocardiographic images.</p>
<p>In conclusion, we present a multimodular AI algorithm that provides automated, accurate, and rapid assessment of both LVEF and regional wall motion abnormalities from standard 2D echocardiographic images in patients with ischemic heart disease. The algorithm demonstrates performance comparable to expert cardiologists and shows promise as a clinical decision support tool. Prospective validation studies and integration into clinical workflows are warranted to realize the full potential of this technology.</p>
</section>

<section id="references">
<h3>References</h3>
<ol class="references-list">
<li>Roth GA, Mensah GA, Johnson CO, et al. Global burden of cardiovascular diseases and risk factors, 1990-2019: update from the GBD 2019 study. J Am Coll Cardiol. 2020;76(25):2982-3021.</li>
<li>Ibanez B, James S, Agewall S, et al. 2017 ESC guidelines for the management of acute myocardial infarction in patients presenting with ST-segment elevation. Eur Heart J. 2018;39(2):119-177.</li>
<li>Lang RM, Badano LP, Mor-Avi V, et al. Recommendations for cardiac chamber quantification by echocardiography in adults: an update from the American Society of Echocardiography and the European Association of Cardiovascular Imaging. J Am Soc Echocardiogr. 2015;28(1):1-39.e14.</li>
<li>Thavendiranathan P, Grant AD, Negishi T, Plana JC, Popovic ZB, Marwick TH. Reproducibility of echocardiographic techniques for sequential assessment of left ventricular ejection fraction and volumes: application to patients undergoing cancer chemotherapy. J Am Coll Cardiol. 2013;61(1):77-84.</li>
<li>Farsalinos KE, Daraban AM, Unlu S, Thomas JD, Badano LP, Voigt JU. Head-to-head comparison of global longitudinal strain measurements among nine different vendors: the EACVI/ASE inter-vendor comparison study. J Am Soc Echocardiogr. 2015;28(10):1171-1181.e2.</li>
<li>Hoffmann R, Lethen H, Marwick T, et al. Analysis of interinstitutional observer agreement in interpretation of dobutamine stress echocardiograms. J Am Coll Cardiol. 1996;27(2):330-336.</li>
<li>Dey D, Slomka PJ, Leeson P, et al. Artificial intelligence in cardiovascular imaging: JACC state-of-the-art review. J Am Coll Cardiol. 2019;73(11):1317-1335.</li>
<li>Litjens G, Ciompi F, Wolterink JM, et al. State-of-the-art deep learning in cardiovascular image analysis. JACC Cardiovasc Imaging. 2019;12(8 Pt 1):1549-1565.</li>
<li>Zhang J, Gajjala S, Agrawal P, et al. Fully automated echocardiogram interpretation in clinical practice: feasibility and diagnostic accuracy. Circulation. 2018;138(16):1623-1635.</li>
<li>Salte IM, Ostvik A, Smistad E, et al. Artificial intelligence for automatic measurement of left ventricular strain in echocardiography. JACC Cardiovasc Imaging. 2021;14(10):1918-1928.</li>
<li>Cerqueira MD, Weissman NJ, Dilsizian V, et al. Standardized myocardial segmentation and nomenclature for tomographic imaging of the heart. Circulation. 2002;105(4):539-542.</li>
<li>Ouyang D, He B, Ghorbani A, et al. Video-based AI for beat-to-beat assessment of cardiac function. Nature. 2020;580(7802):252-256.</li>
<li>Kusunose K, Haga A, Abe T, Sata M. Utilization of artificial intelligence in echocardiography. Circ J. 2019;83(8):1623-1629.</li>
<li>Huang MS, Wang CS, Chiang JH, Liu PY, Tsai WC. Automated recognition of regional wall motion abnormalities through deep neural network interpretation of transthoracic echocardiography. Circulation. 2020;142(16):1510-1520.</li>
<li>Kelly CJ, Karthikesalingam A, Suleyman M, Corrado G, King D. Key challenges for delivering clinical impact with artificial intelligence. BMC Med. 2019;17(1):195.</li>
<li>Narang A, Bae R, Hong H, et al. Utility of a deep-learning algorithm to guide novices to acquire echocardiograms for limited diagnostic use. JAMA Cardiol. 2021;6(6):624-632.</li>
<li>Tromp J, Seekings PJ, Hung CL, et al. Automated interpretation of systolic and diastolic function on the echocardiogram: a multicohort study. Lancet Digit Health. 2022;4(1):e46-e54.</li>
<li>Ghorbani A, Ouyang D, Abid A, et al. Deep learning interpretation of echocardiograms. NPJ Digit Med. 2020;3:10.</li>
<li>He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016:770-778.</li>
<li>Ronneberger O, Fischer P, Brox T. U-Net: convolutional networks for biomedical image segmentation. In: Medical Image Computing and Computer-Assisted Intervention. 2015:234-241.</li>
</ol>
</section>