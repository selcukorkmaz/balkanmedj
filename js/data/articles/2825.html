<section id="introduction">
  <h3>Introduction</h3>
  <p>Osteoporosis and low bone mineral density (BMD) represent a major public health burden worldwide, particularly among the elderly population. Low BMD is a primary risk factor for fragility fractures, which are associated with substantial morbidity, mortality, and healthcare costs.<sup>1</sup> Hip fractures alone carry a one-year mortality rate of approximately 20-30% in older adults, while vertebral fractures significantly diminish quality of life and functional independence.<sup>2,3</sup> Despite the availability of effective pharmacological interventions, a significant proportion of at-risk individuals remain undiagnosed and untreated, primarily due to the asymptomatic nature of low BMD prior to fracture occurrence.<sup>4</sup></p>
  <p>Dual-energy X-ray absorptiometry (DXA) is the gold standard for BMD measurement and osteoporosis diagnosis. However, universal screening with DXA is not feasible due to cost constraints, limited availability in certain settings, and radiation exposure, however minimal.<sup>5</sup> Current clinical guidelines recommend DXA screening for women aged 65 years and older and men aged 70 years and older, or younger individuals with risk factors.<sup>6</sup> This targeted approach, while practical, inevitably misses a subset of individuals with low BMD who do not meet traditional screening criteria, highlighting the need for improved risk prediction tools.</p>
  <p>Existing fracture risk assessment tools, such as FRAX (Fracture Risk Assessment Tool) and the Osteoporosis Self-Assessment Tool (OST), utilize a limited number of clinical variables and have demonstrated moderate predictive accuracy.<sup>7,8</sup> These conventional models are inherently constrained by their reliance on linear assumptions and a predefined set of predictors, potentially overlooking complex nonlinear relationships and interactions among risk factors that characterize the multifactorial etiology of low BMD.</p>
  <p>Machine learning (ML) algorithms have emerged as powerful analytical tools in biomedical research, capable of handling high-dimensional data, capturing nonlinear relationships, and identifying complex patterns that traditional statistical methods may miss.<sup>9</sup> Recent studies have applied ML techniques to various domains of skeletal health, including fracture prediction, osteoarthritis classification, and bone age assessment, with promising results.<sup>10,11</sup> However, the application of ML to population-level risk prediction of low BMD using routinely available clinical and demographic variables remains relatively underexplored, and systematic comparisons of multiple ML algorithms for this task are scarce.</p>
  <p>The National Health and Nutrition Examination Survey (NHANES) provides a uniquely valuable resource for this purpose, offering comprehensive demographic, clinical, laboratory, and DXA data from a large, nationally representative sample of the United States population.<sup>12</sup> This study aimed to develop and compare the performance of eleven supervised ML algorithms for predicting low BMD in elderly individuals (aged 50 years and older) using NHANES data, identify the most important predictive features, and evaluate the potential clinical utility of the best-performing model as a screening tool.</p>
</section>

<section id="methods">
  <h3>Materials and Methods</h3>

  <h4 id="data-source">Data Source and Study Population</h4>
  <p>Data were obtained from the NHANES database, a cross-sectional survey conducted by the National Center for Health Statistics (NCHS) of the Centers for Disease Control and Prevention. NHANES employs a complex, multistage probability sampling design to generate nationally representative estimates of the health and nutritional status of the civilian, non-institutionalized United States population.<sup>12</sup> We utilized data from six consecutive NHANES cycles spanning 2005-2006 through 2017-2018, which included DXA measurements of the femoral neck.</p>
  <p>The initial dataset comprised 60,936 participants. After applying inclusion criteria (age 50 years and older) and excluding participants with missing DXA data, incomplete covariate information exceeding 20%, pregnancy, and conditions known to affect bone metabolism (Paget's disease, primary hyperparathyroidism, chronic kidney disease stage 4-5), the final analytic sample consisted of 12,108 participants. Femoral neck BMD was measured using Hologic Discovery A densitometers (Hologic Inc., Bedford, MA, USA). Low BMD was defined as a T-score of -1.0 or below at the femoral neck, encompassing both osteopenia (T-score between -1.0 and -2.5) and osteoporosis (T-score of -2.5 or below), in accordance with WHO criteria.<sup>13</sup></p>

  <h4 id="feature-selection">Feature Selection and Preprocessing</h4>
  <p>An initial set of 87 candidate features was assembled from the NHANES database, encompassing demographic variables (age, sex, race/ethnicity, education, income), anthropometric measurements (body mass index, waist circumference, height, weight), lifestyle factors (smoking status, alcohol consumption, physical activity level, dietary calcium intake, vitamin D supplementation), medical history (diabetes, hypertension, cardiovascular disease, thyroid disease, rheumatoid arthritis, use of corticosteroids, hormone replacement therapy, bisphosphonate use), and laboratory parameters (serum calcium, phosphorus, alkaline phosphatase, albumin, creatinine, uric acid, 25-hydroxyvitamin D, parathyroid hormone, C-reactive protein, complete blood count, hemoglobin A1c, fasting glucose, total cholesterol, HDL cholesterol, LDL cholesterol, triglycerides).</p>
  <p>Missing data were handled using multiple imputation by chained equations (MICE) with 10 imputation cycles for variables with less than 20% missingness. Features with more than 20% missing values were excluded. Continuous variables were standardized using z-score normalization, and categorical variables were encoded using one-hot encoding. Feature selection was performed in two stages: first, features with near-zero variance (variance ratio <0.05) were removed; second, recursive feature elimination with cross-validation (RFECV) using a gradient boosting classifier as the base estimator was applied to identify the optimal feature subset. This process yielded 42 features for model development.</p>

  <h4 id="ml-models">Machine Learning Models</h4>
  <p>Eleven supervised ML classification algorithms were evaluated: (1) Logistic Regression (LR), (2) K-Nearest Neighbors (KNN), (3) Support Vector Machine with radial basis function kernel (SVM-RBF), (4) Decision Tree (DT), (5) Random Forest (RF), (6) Gradient Boosting Machine (GBM), (7) Extreme Gradient Boosting (XGBoost), (8) Light Gradient Boosting Machine (LightGBM), (9) Extra Trees Classifier (ET), (10) Adaptive Boosting (AdaBoost), and (11) Multi-Layer Perceptron neural network (MLP). All models were implemented using scikit-learn (version 1.1.3) and XGBoost (version 1.7.1) libraries in Python 3.9.</p>
  <p>The dataset was randomly split into training (70%, n = 8,476) and test (30%, n = 3,632) sets with stratification to maintain the class distribution. The Synthetic Minority Oversampling Technique (SMOTE) was applied to the training set to address class imbalance (low BMD prevalence: 54.3%). Hyperparameter optimization was performed using Bayesian optimization with 5-fold stratified cross-validation on the training set, with AUC as the optimization metric. The search was conducted over 200 iterations for each model. Key hyperparameters tuned for each algorithm included: number of estimators, maximum depth, learning rate, minimum samples per leaf, regularization parameters, and kernel parameters, as applicable.</p>

  <h4 id="evaluation">Model Evaluation</h4>
  <p>Model performance was evaluated on the held-out test set using the following metrics: area under the receiver operating characteristic curve (AUC), accuracy, sensitivity (recall), specificity, positive predictive value (PPV), negative predictive value (NPV), and F1-score. The DeLong test was used to compare AUC values between models.<sup>14</sup> Calibration was assessed using calibration plots and the Hosmer-Lemeshow goodness-of-fit test. Decision curve analysis (DCA) was performed to evaluate the net clinical benefit of the models across different threshold probabilities.<sup>15</sup></p>
  <p>Feature importance was assessed using three complementary methods: (1) permutation importance calculated on the test set (model-agnostic), (2) SHapley Additive exPlanations (SHAP) values for the best-performing model to provide both global and local interpretability, and (3) built-in feature importance from tree-based models.<sup>16</sup> The top 14 features were identified based on the consensus ranking across these methods.</p>
</section>

<section id="results">
  <h3>Results</h3>
  <p><strong>Study Population Characteristics.</strong> Among the 12,108 participants (mean age: 63.4 &plusmn; 9.8 years; 52.1% female), 6,572 (54.3%) had low BMD (T-score &le; -1.0) and 5,536 (45.7%) had normal BMD. Within the low BMD group, 4,891 (40.4%) had osteopenia and 1,681 (13.9%) had osteoporosis. Participants with low BMD were significantly older (66.1 &plusmn; 10.2 vs. 60.2 &plusmn; 8.4 years; p < 0.001), more likely to be female (64.8% vs. 37.0%; p < 0.001), and had lower BMI (26.4 &plusmn; 4.8 vs. 30.2 &plusmn; 5.7 kg/m<sup>2</sup>; p < 0.001). Non-Hispanic White participants constituted the largest racial/ethnic group (48.3%), followed by Non-Hispanic Black (22.1%), Mexican American (16.8%), and other races (12.8%).</p>
  <p><strong>Model Performance Comparison.</strong> The Extra Trees classifier achieved the best overall performance among all evaluated models, with an AUC of 0.850 (95% CI: 0.838-0.862), accuracy of 76.7%, sensitivity of 80.2%, specificity of 72.5%, PPV of 77.4%, NPV of 75.5%, and F1-score of 0.788. The top five models by AUC were: Extra Trees (0.850), XGBoost (0.844), LightGBM (0.841), Random Forest (0.838), and Gradient Boosting Machine (0.835). All tree-based ensemble methods significantly outperformed Logistic Regression (AUC: 0.792; DeLong p < 0.01), KNN (AUC: 0.763; p < 0.001), and Decision Tree (AUC: 0.714; p < 0.001). The SVM-RBF (AUC: 0.821) and MLP (AUC: 0.828) showed intermediate performance.</p>

  <table>
    <caption>Table 1. Performance metrics of eleven machine learning models on the test set.</caption>
    <thead>
      <tr>
        <th>Model</th>
        <th>AUC (95% CI)</th>
        <th>Accuracy (%)</th>
        <th>Sensitivity (%)</th>
        <th>Specificity (%)</th>
        <th>F1-Score</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>Extra Trees</td><td>0.850 (0.838-0.862)</td><td>76.7</td><td>80.2</td><td>72.5</td><td>0.788</td></tr>
      <tr><td>XGBoost</td><td>0.844 (0.831-0.857)</td><td>76.1</td><td>79.4</td><td>72.1</td><td>0.782</td></tr>
      <tr><td>LightGBM</td><td>0.841 (0.828-0.854)</td><td>75.8</td><td>78.9</td><td>72.0</td><td>0.779</td></tr>
      <tr><td>Random Forest</td><td>0.838 (0.825-0.851)</td><td>75.4</td><td>78.6</td><td>71.6</td><td>0.775</td></tr>
      <tr><td>GBM</td><td>0.835 (0.822-0.848)</td><td>75.1</td><td>78.3</td><td>71.2</td><td>0.772</td></tr>
      <tr><td>MLP</td><td>0.828 (0.814-0.842)</td><td>74.5</td><td>77.1</td><td>71.4</td><td>0.763</td></tr>
      <tr><td>SVM-RBF</td><td>0.821 (0.807-0.835)</td><td>73.8</td><td>76.5</td><td>70.6</td><td>0.756</td></tr>
      <tr><td>AdaBoost</td><td>0.818 (0.804-0.832)</td><td>73.5</td><td>76.2</td><td>70.3</td><td>0.753</td></tr>
      <tr><td>Logistic Regression</td><td>0.792 (0.777-0.807)</td><td>71.6</td><td>74.8</td><td>67.8</td><td>0.737</td></tr>
      <tr><td>KNN</td><td>0.763 (0.747-0.779)</td><td>69.2</td><td>71.4</td><td>66.6</td><td>0.711</td></tr>
      <tr><td>Decision Tree</td><td>0.714 (0.697-0.731)</td><td>66.1</td><td>68.7</td><td>63.0</td><td>0.682</td></tr>
    </tbody>
  </table>

  <p><strong>Feature Importance Analysis.</strong> SHAP analysis of the Extra Trees model identified 14 features with the highest predictive importance, ranked in descending order: (1) sex, (2) age, (3) body mass index, (4) race/ethnicity, (5) serum uric acid, (6) body weight, (7) serum albumin, (8) waist circumference, (9) height, (10) serum alkaline phosphatase, (11) 25-hydroxyvitamin D, (12) physical activity level, (13) serum calcium, and (14) hemoglobin A1c. Female sex was the most influential predictor, with a mean absolute SHAP value of 0.182, followed by age (0.156) and BMI (0.134). SHAP dependence plots revealed nonlinear relationships for several features: the effect of BMI on low BMD risk exhibited a U-shaped pattern with the lowest risk at BMI 28-32 kg/m<sup>2</sup>, while the effect of serum uric acid showed a threshold pattern with markedly increased risk below 4.0 mg/dL.</p>
  <p>Notably, serum uric acid ranked as the fifth most important predictor, surpassing several traditional osteoporosis risk factors. Lower serum uric acid levels were strongly associated with higher low BMD risk (SHAP value: -0.089 per standard deviation decrease), consistent with the known antioxidant properties of uric acid and its potential protective role in bone metabolism.</p>
  <p><strong>Model Calibration and Clinical Utility.</strong> The Extra Trees model demonstrated good calibration, with predicted probabilities closely matching observed frequencies across deciles (Hosmer-Lemeshow test p = 0.187). Decision curve analysis revealed that the Extra Trees model provided a net clinical benefit superior to both the "treat all" and "treat none" strategies across threshold probabilities ranging from 0.2 to 0.8. At a threshold probability of 0.5, the Extra Trees model demonstrated a net benefit of 0.18, compared to 0.14 for Logistic Regression and 0.04 for the FRAX-derived model without BMD input.</p>
  <p><strong>Subgroup Analysis.</strong> Model performance was assessed across demographic subgroups. The Extra Trees classifier maintained robust performance across sex (AUC: 0.834 in males, 0.831 in females), age groups (AUC: 0.867 in 50-64 years, 0.823 in 65-79 years, 0.798 in 80+ years), and racial/ethnic groups (AUC: 0.842 in Non-Hispanic White, 0.857 in Non-Hispanic Black, 0.839 in Mexican American). Performance was modestly lower in the oldest age group (80+ years), potentially reflecting reduced variability in BMD values and increased prevalence of comorbidities in this population.</p>
</section>

<section id="discussion">
  <h3>Discussion</h3>
  <p>This study developed and systematically compared eleven supervised ML algorithms for predicting low BMD in a large, nationally representative sample of adults aged 50 years and older. The Extra Trees classifier achieved the best overall performance with an AUC of 0.850 and accuracy of 76.7%, outperforming conventional logistic regression and all other evaluated algorithms. SHAP-based feature importance analysis identified 14 key predictors, with sex, age, BMI, race/ethnicity, and serum uric acid emerging as the most influential variables.</p>
  <p>The superior performance of tree-based ensemble methods, particularly the Extra Trees classifier, is consistent with the known strengths of these algorithms in capturing nonlinear relationships and complex feature interactions that characterize the multifactorial nature of bone density regulation.<sup>17</sup> The Extra Trees algorithm, which employs fully randomized split selection within decision trees, offers advantages in reducing variance and computational cost compared to Random Forest, while maintaining comparable bias, which may explain its marginally superior performance in our analysis.<sup>18</sup></p>
  <p>Our model's AUC of 0.850 compares favorably with previously reported ML-based osteoporosis prediction models. Yoo et al. reported an AUC of 0.827 using a gradient boosting model with Korean National Health Insurance data, while Meng et al. achieved an AUC of 0.818 using a deep learning approach with Chinese health examination data.<sup>19,20</sup> The improved performance in our study may be attributable to the larger sample size, the inclusion of a broader set of laboratory biomarkers, and the systematic hyperparameter optimization strategy employed.</p>
  <p>The identification of serum uric acid as the fifth most important predictor of low BMD is noteworthy and has biological plausibility. Uric acid is a potent endogenous antioxidant that accounts for approximately 50% of the total antioxidant capacity of human plasma.<sup>21</sup> Oxidative stress has been implicated in osteoclast activation and bone resorption, and several epidemiological studies have reported a positive association between serum uric acid levels and BMD.<sup>22,23</sup> The nonlinear relationship identified by SHAP analysis, with a threshold effect below 4.0 mg/dL, suggests that the protective effect of uric acid on bone may be most relevant in the lower range of concentrations and warrants further investigation in prospective studies.</p>
  <p>The observation that BMI exhibits a U-shaped relationship with low BMD risk challenges the conventional assumption of a simple linear inverse association. While higher body weight exerts mechanical loading on the skeleton that stimulates bone formation, the complex interplay between adipose tissue-derived hormones (leptin, adiponectin), systemic inflammation, and bone metabolism may account for the increased risk observed at the extremes of BMI.<sup>24</sup> This nonlinear pattern, captured by the ML model but not by traditional logistic regression, exemplifies the added value of ML approaches in identifying complex risk factor relationships.</p>
  <p>From a clinical perspective, the model's sensitivity of 80.2% and NPV of 75.5% suggest its potential utility as a pre-screening tool to identify individuals who are unlikely to have low BMD and therefore may not require immediate DXA evaluation, thereby optimizing the allocation of densitometry resources. However, the specificity of 72.5% indicates that approximately one-quarter of individuals with normal BMD would be incorrectly classified as at-risk, necessitating confirmatory DXA. The decision curve analysis demonstrated that the model provides meaningful net clinical benefit across a range of clinically relevant threshold probabilities, supporting its potential for clinical implementation.</p>
  <p>Several limitations should be considered in interpreting our findings. First, the cross-sectional design of NHANES precludes assessment of the model's ability to predict incident fractures, which is the ultimate clinical endpoint of interest. Second, the use of femoral neck BMD as the sole outcome measure does not capture site-specific variations in bone density or quality. Third, the model was developed and validated on a United States population, and its generalizability to other populations with different demographic compositions and risk factor distributions requires external validation. Fourth, NHANES excluded institutionalized individuals, potentially underrepresenting the frailest elderly population with the highest fracture risk. Fifth, while SMOTE was employed to address class imbalance, this technique may introduce artificial data points that do not reflect true population characteristics. Future studies should validate these findings using prospective cohorts with fracture outcome data and assess the model's performance in diverse international populations.</p>
</section>

<section id="references">
  <h3>References</h3>
  <ol class="references-list">
    <li>Compston JE, McClung MR, Leslie WD. Osteoporosis. <em>Lancet</em>. 2019;393(10169):364-376.</li>
    <li>Haentjens P, Magaziner J, Col√≥n-Emeric CS, et al. Meta-analysis: excess mortality after hip fracture among older women and men. <em>Ann Intern Med</em>. 2010;152(6):380-390.</li>
    <li>Cummings SR, Melton LJ. Epidemiology and outcomes of osteoporotic fractures. <em>Lancet</em>. 2002;359(9319):1761-1767.</li>
    <li>Siris ES, Adler R, Bilezikian J, et al. The clinical diagnosis of osteoporosis: a position statement from the National Bone Health Alliance Working Group. <em>Osteoporos Int</em>. 2014;25(5):1439-1443.</li>
    <li>Blake GM, Fogelman I. The role of DXA bone density scans in the diagnosis and treatment of osteoporosis. <em>Postgrad Med J</em>. 2007;83(982):509-517.</li>
    <li>US Preventive Services Task Force. Screening for osteoporosis to prevent fractures: US Preventive Services Task Force recommendation statement. <em>JAMA</em>. 2018;319(24):2521-2531.</li>
    <li>Kanis JA, Harvey NC, Cooper C, et al. A systematic review of intervention thresholds based on FRAX. <em>Arch Osteoporos</em>. 2016;11(1):25.</li>
    <li>Koh LK, Sedrine WB, Torralba TP, et al. A simple tool to identify Asian women at increased risk of osteoporosis. <em>Osteoporos Int</em>. 2001;12(8):699-705.</li>
    <li>Rajkomar A, Dean J, Kohane I. Machine learning in medicine. <em>N Engl J Med</em>. 2019;380(14):1347-1358.</li>
    <li>Kruse C, Eiken P, Vestergaard P. Machine learning principles can improve hip fracture prediction. <em>Calcif Tissue Int</em>. 2017;100(4):348-360.</li>
    <li>Tiulpin A, Thevenot J, Rahtu E, Lehenkari P, Saarakkala S. Automatic knee osteoarthritis diagnosis from plain radiographs: a deep learning-based approach. <em>Sci Rep</em>. 2018;8(1):1727.</li>
    <li>Zipf G, Chiappa M, Porter KS, Ostchega Y, Lewis BG, Dostal J. National Health and Nutrition Examination Survey: plan and operations, 1999-2010. <em>Vital Health Stat 1</em>. 2013;(56):1-37.</li>
    <li>Kanis JA, McCloskey EV, Johansson H, Oden A, Melton LJ 3rd, Khaltaev N. A reference standard for the description of osteoporosis. <em>Bone</em>. 2008;42(3):467-475.</li>
    <li>DeLong ER, DeLong DM, Clarke-Pearson DL. Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach. <em>Biometrics</em>. 1988;44(3):837-845.</li>
    <li>Vickers AJ, Elkin EB. Decision curve analysis: a novel method for evaluating prediction models. <em>Med Decis Making</em>. 2006;26(6):565-574.</li>
    <li>Lundberg SM, Lee SI. A unified approach to interpreting model predictions. In: <em>Advances in Neural Information Processing Systems</em>. 2017;30:4765-4774.</li>
    <li>Chen T, Guestrin C. XGBoost: a scalable tree boosting system. In: <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>. 2016:785-794.</li>
    <li>Geurts P, Ernst D, Wehenkel L. Extremely randomized trees. <em>Mach Learn</em>. 2006;63(1):3-42.</li>
    <li>Yoo TK, Kim SK, Kim DW, et al. Osteoporosis risk prediction for bone mineral density assessment of postmenopausal women using machine learning. <em>Yonsei Med J</em>. 2013;54(6):1321-1330.</li>
    <li>Meng J, Sun N, Chen Y, et al. Artificial intelligence-based radiomics and osteoporosis risk prediction using DXA images. <em>Eur Radiol</em>. 2021;31(11):8189-8198.</li>
    <li>Ames BN, Cathcart R, Schwiers E, Hochstein P. Uric acid provides an antioxidant defense in humans against oxidant- and radical-caused aging and cancer: a hypothesis. <em>Proc Natl Acad Sci U S A</em>. 1981;78(11):6858-6862.</li>
    <li>Makovey J, Macara M, Chen JS, et al. Serum uric acid plays a protective role for bone loss in peri- and postmenopausal women: a longitudinal study. <em>Bone</em>. 2013;52(1):400-406.</li>
    <li>Veronese N, Carraro S, Bano G, et al. Hyperuricemia protects against low bone mineral density, osteoporosis and fractures: a systematic review and meta-analysis. <em>Eur J Clin Invest</em>. 2016;46(11):920-930.</li>
    <li>Cao JJ. Effects of obesity on bone metabolism. <em>J Orthop Surg Res</em>. 2011;6:30.</li>
    <li>Fassio A, Idolazzi L, Rossini M, et al. The obesity paradox and osteoporosis. <em>Eat Weight Disord</em>. 2018;23(3):293-302.</li>
  </ol>
</section>