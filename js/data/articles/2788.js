window._articleFullText = window._articleFullText || {};
window._articleFullText[2788] = "<div class=\"col-lg-12 col-md-12 col-sm-12 col-xs-12\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t<div  style=\"width:100%; float:left;  padding-bottom:0px;\">\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t<div\tstyle=\"width:100%; float:left; min-height:45px; text-align:justify\">\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t<a href=\"\" name=\"summary_en\"></a>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t<!--<h2>Summary</h2>-->\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t<h4>Abstract</h4>\r\n<p><strong>Background:</strong> Low bone mineral density (BMD) is a common age-related condition that elevates the risk of fractures and mortality. Machine learning (ML) techniques offer a promising approach for early prediction using readily available clinical, biochemical, and demographic data.</p>\r\n<p><strong>Aims:</strong> To evaluate the predictive performance of eleven ML models in identifying low BMD and to determine the most influential risk factors using the best-performing model.</p>\r\n<p><strong>Study Design:</strong> Cross-sectional study.</p>\r\n<p><strong>Methods:</strong> Data were obtained from National Health and Nutrition Examination Survey (2005-2010, 2013-2014, and 2017-2020), focusing on individuals aged &ge; 50 years with available femoral neck or total femur BMD data. After applying exclusion criteria, 12,108 participants were included. Supervised ML algorithms were trained using 57 clinical, biochemical, demographic, and behavioral features. Model performance was assessed using accuracy, area under the curve (AUC), recall, precision, and F1 score. SHAP analysis was employed to interpret model outputs and rank predictors.</p>\r\n<p><strong>Results:</strong> The extra trees classifier outperformed other ML methods, achieving an accuracy of 76.7% and an AUC of 0.85. Recursive Feature Elimination with Cross-Validation identified 14 key predictors of low BMD in descending order of importance: sex, age, body mass index, race, family income-to-poverty ratio, serum uric acid, diabetes status, HDL cholesterol, urinary creatinine, alkaline phosphatase, mean cell volume, lymphocyte count, diastolic blood pressure, and glycohemoglobin.</p>\r\n<p><strong>Conclusion:</strong> Tree-based ML models, particularly Extra Trees, can effectively predict low BMD. The identified risk factors include both established and lesser-studied predictors. These findings support the use of ML for personalized osteoporosis and osteopenia screening and highlight its ability to capture complex, multifactorial relationships in population health data.</p>\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t<!--\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t<div\tstyle=\"width:20%; float:left; min-height:150px; padding:10px; padding-top:40px;\">\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t\t\t\t<a class=\"selected_menu\" href=\"#summary_en\">Summary</a><a class=\"menu\" href=\"#introduction\">Introduction</a><a class=\"menu\" href=\"#reference\">Reference</a>\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t-->\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t<div  style=\"width:100%; float:left;  padding-bottom:0px;\">\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t<div\tstyle=\"width:100%; float:left; min-height:45px; text-align:justify\">\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t<a href=\"\" name=\"introduction\"></a>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t<!--<h2>Introduction</h2>-->\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t<hr size=\"1\" color=\"#f2f2f2\">\r\n<h3>INTRODUCTION</h3>\r\n<p>Bone mineral density (BMD) declines with age, depending on the bone mass, leading to osteopenia and, in more advanced stages, osteoporosis.<sup>1</sup> This condition is a major global public health concern that adversely affects the quality of life of millions worldwide. Low bone density affects approximately 200 million individuals globally, including 54 million older adults in the United States (US).<sup>2</sup> It is a key risk factor for hip fractures, which is one of the most serious consequences of falls in older adults, with a 1-year mortality rate of 30%.<sup>3</sup> Although this issue is often highlighted in postmenopausal women, it also significantly affects men, who account for nearly one-third of all hip fractures and experience poorer outcomes.<sup>4</sup></p>\r\n<p>Dual-energy X-ray absorptiometry (DXA) is a non-invasive imaging technique that accurately assesses bone density and strength using low radiation and is considered the gold standard for osteoporosis screening. Areal BMD measured by DXA is converted to a T-score based on the mean and standard deviation (SD) of a young adult reference group: a T-score &gt; -1.0 is considered normal, between -1.0 and -2.5 indicates osteopenia, and &le; -2.5 defines osteoporosis, according to the World Health Organization.<sup>1</sup> Early detection of low bone density, particularly among individuals with T-scores &lt; -1.0 but not yet osteoporotic, is essential for timely intervention and fracture prevention.</p>\r\n<p>In recent years, machine learning (ML) techniques have shown considerable potential in the early diagnosis and risk stratification of chronic diseases, including musculoskeletal disorders.<sup>5-9</sup> ML algorithms can identify complex, non-linear patterns within clinical and demographic data, enabling more precise prediction of low bone density compared with traditional statistical methods. However, the comparative performance of different ML models in predicting low bone density remains insufficiently explored.</p>\r\n<p>The aim of this study was to (1) compare the predictive performance of 11 ML algorithms in identifying individuals with low bone density using the publicly available National Health and Nutrition Examination Survey (NHANES) dataset, and (2) to identify the most influential predictors of low bone density using the best-performing model. The insights gained from this research are expected to support evidence-based clinical decision-making and guide future studies toward personalized interventions for osteoporosis prevention and management.</p>\r\n<h3>MATERIALS AND METHODS</h3>\r\n<p><strong><em>Study population and data source</em></strong></p>\r\n<p>This study utilized data from selected cycles of the NHANES, a nationally representative program conducted by the National Center for Health Statistics under the Centers for Disease Control and Prevention (https://wwwn.cdc.gov/nchs/nhanes/). NHANES employed a stratified, multistage probability sampling design to obtain health-related data from the civilian, noninstitutionalized US population. Data obtained from the periods of 2005-2010, 2013-2014, and 2017-2020 were included in the study based on the availability of BMD values (g/cm<sup>2</sup>) obtained by DXA using Hologic QDR 4500A fan-beam densitometers (Hologic Inc., Bedford, MA, USA).<sup>10 </sup>The dataset also included information on the sociodemographic characteristics (e.g., age, sex, race/ethnicity, education), behavioral factors (e.g., smoking habits, physical activity, alcohol use), clinical parameters [e.g., body mass index (BMI), blood pressure], and biochemical markers (e.g., serum vitamin D, calcium, phosphorus).</p>\r\n<p>Femoral neck and total femur BMD measurements were evaluated to deduce the low bone density. An individual with a femoral neck or total femur T-score value of &lt; -1 was classified into the low bone-density group. T-scores were calculated using the following formula:</p>\r\n<p>T-score = [individual BMD-mean BMD (reference population)]/SD (reference population).</p>\r\n<p>The reference means and SD values were derived from the NHANES III reference data, as published by Looker et al.<sup>11</sup></p>\r\n<p>Individuals&nbsp;who met the following&nbsp;criteria were&nbsp;excluded: (1)&nbsp;those&nbsp;aged &lt; 50 years, (2)&nbsp;those&nbsp;without BMD measurements at&nbsp;the femoral neck or total femur, and (3)&nbsp;those with&nbsp;a history of cancer diagnosis. Based on these criteria, 12,108 participants were enrolled in the study. The exclusion criteria applied in the study are depicted in <a href=\"javascript:openWin('uploads/grafik/figure_BMJ_2788_0.jpg', 640, 480)\"><b>Figure 1</b></a>.</p>\r\n<p><strong><em>Data preprocessing</em></strong></p>\r\n<p>The procedure outlined below was implemented to prepare the data for the analysis. As&nbsp;a&nbsp;first&nbsp;step in&nbsp;data&nbsp;preparation, variables with &gt; 30% missing values were removed from the dataset.</p>\r\n<p>Missing value imputation: Missing data of continuous features were imputed using the K-nearest neighbors (KNN) method, which estimates missing values based on the similarity of feature patterns among the closest observations in the dataset, and the&nbsp;most frequent&nbsp;category&nbsp;was&nbsp;used&nbsp;for&nbsp;imputing&nbsp;categorical&nbsp;variables.</p>\r\n<p><strong>Categorical encoding:</strong> Nominal features were converted to numerical form via one-hot encoding.</p>\r\n<p><strong>Feature scaling:</strong> All continuous variables were standardized using z-score normalization to ensure comparability across features. The standardized value z for a given observation x was computed was computed using the following formula:</p>\r\n<p>z<sub>i </sub>= (x<sub>i</sub>&minus;&mu;)/&sigma;,</p>\r\n<p>where, x<sub>i</sub> represents the i<sup>th</sup> individual&rsquo;s value, &mu; is the mean of the feature, and &sigma; is the SD of the feature.</p>\r\n<p>Multicollinearity: Features with a correlation coefficient &gt; 0.80 or &lt; -0.80 were identified and removed to reduce multicollinearity.</p>\r\n<p>Feature selection: In&nbsp;order&nbsp;to optimize&nbsp;the model performance and&nbsp;decrease&nbsp;overfitting, feature selection was applied based on the Light Gradient Boosting Machine (LightGBM) algorithm. LightGBM calculates feature importance scores during the model training process by evaluating each variable&rsquo;s contribution to information gain across decision trees. The importance scores are used to rank the input variables, and the least informative features are removed from the dataset. In this study, the threshold for selection was set to retain the top 20% of features with the highest importance scores.</p>\r\n<p><strong>Data splitting:</strong> The dataset was randomly partitioned into a training set (80%) and a testing set (20%). Feature selection, model fitting, and hyperparameter tuning were performed solely on the training set, and the final model performance metrics were evaluated on the testing set.</p>\r\n<p><strong>Cross-validation:</strong> We employed 10‑fold cross‑validation on the training set to assess model generalizability and guard against overfitting. The data were randomly split into ten equally sized folds, and, in each iteration, nine folds were used to fit the model and optimize hyperparameters, whereas the remaining fold was used as the validation set. Performance metrics [e.g., area under the curve (AUC), accuracy] were computed for each fold and then averaged to provide a robust estimate of model performance before the ultimate assessment on the withheld test dataset.</p>\r\n<p>To avoid data leakage, all preprocessing steps (including imputation, encoding, scaling, feature selection, and feature elimination) were implemented within a strictly nested pipeline. These transformations were fitted exclusively on the training folds during cross-validation and subsequently applied to the corresponding validation fold, whereas the held-out test set was used only for the final model evaluation.</p>\r\n<p><strong><em>Machine learning algorithms</em></strong></p>\r\n<p>A comprehensive array of supervised classification algorithms, including ensemble tree&nbsp;techniques, gradient-based&nbsp;learning systems, linear models, kernel machines,&nbsp;and instance-based&nbsp;methodologies, was used in the study.</p>\r\n<p><strong><em>Extra trees classifier</em></strong></p>\r\n<p>The ET is an ensemble learning approach that relies on randomly generating numerous&nbsp;decision trees. This strategy differs from the conventional decision trees by employing entirely random threshold values at the node separation for each tree, which&nbsp;enhances&nbsp;the variety among the models. This randomization plays a role in preventing overfitting and presents robust performance on noisy datasets.<sup>12</sup></p>\r\n<p><strong><em>Random forest classifier</em></strong></p>\r\n<p>RF constructs multiple decision trees with bootstrapped subsets of the training data and integrates their predictions through majority voting. The procedure incorporates randomness in two ways: first, by sampling the data, and second, by selecting a random subset of features at each node to determine the optimal split. This approach helps reduce the variance of individual decision trees and prevents overfitting, which is common in single-tree models.<sup>13</sup></p>\r\n<p><strong><em>LightGBM </em></strong></p>\r\n<p>LightGBM is a gradient‑boosted algorithm that constructs trees by prioritizing leaves, providing faster training and lower memory usage on big datasets. It leverages histogram-dependent partitioning to efficiently handle a substantial quantity of continuous features.<sup>14</sup></p>\r\n<p><strong><em>Gradient boosting classifier</em></strong></p>\r\n<p>As a sequential ensemble learning framework, the GB builds an additive model by optimizing a loss function using decision trees as weak learners. In contrast to parallel methodologies such as Random Forest, it fits trees in sequence, whereby every new tree aims to correct the residual errors of the prior ensemble of models. This approach offers a highly flexible and powerful model that can identify elaborate nonlinear relationships. Nevertheless, it is also more sensitive to overfitting.<sup>15</sup></p>\r\n<p><strong><em>Logistic regression</em></strong></p>\r\n<p>LR is a linear classification algorithm commonly used due to its simplicity, interpretability, and statistical foundations. It models the probability of a binary outcome utilizing the logistic (sigmoid) function, with the underlying assumption of a linear relationship between the log-odds of the target and the independent variables.<sup>16</sup></p>\r\n<p><strong><em>Linear discriminant analysis</em></strong></p>\r\n<p>LDA assumes normally distributed classes with equal covariance matrices and finds a linear combination of features that maximizes class separation. It is particularly effective when class distributions in scenarios by class distributions that are nearly Gaussian, and the sample sizes are within a moderate range.<sup>17</sup></p>\r\n<p><strong><em>AdaBoost classifier</em></strong></p>\r\n<p>Adaptive Boosting (AdaBoost) is an adaptive boosting algorithm that sequentially fits weak learners by reweighting incorrectly classified instances in every subsequent round. It works by sequentially training models, where each subsequent learner focuses more on the instances that were misclassified by the previous ones. However, this approach can be sensitive to noisy data and outliers.<sup>18</sup></p>\r\n<p><strong><em>Ridge classifier</em></strong></p>\r\n<p>The RC is a regularized version of linear classification that applies an L2 penalty to shrink coefficient estimates. The method reduces overfitting, especially in cases with high-dimensional or collinear data. Though it is similar to LR, this method uses a least-squares loss function rather than a log-likelihood approach.<sup>19</sup></p>\r\n<p><strong><em>Support vector machine</em></strong></p>\r\n<p>SVM is a supervised learning model used for classification tasks, especially when the feature space is high-dimensional. The linear kernel aims to identify the optimal hyperplane that maximally separates classes by maximizing the margin between the closest data points, which is known as support vectors. Although it performs well in big datasets, it may require significant computational resources.<sup>20</sup></p>\r\n<p><strong><em>Decision tree classifier</em></strong></p>\r\n<p>DT is a non-parametric, tree-based supervised learning algorithm that iteratively divides the dataset into smaller partitions, with each division determined by the feature that results in the greatest information gain. Finally, it establishes a tree structure where the leaves represent class labels. It is easy to interpret and visualize, but prone to overfitting without proper pruning.<sup>21</sup></p>\r\n<p><strong><em>K-Nearest neighbors</em></strong></p>\r\n<p>KNN is an instance-driven, non-parametric classification algorithm that assigns class labels based on the majority vote of the &ldquo;k&rdquo; closest neighbors in the feature space. It stores all the training dataset and calculates distances (generally Euclidean) between a new input and existing samples during the prediction process. Despite&nbsp;being&nbsp;simple to implement, this&nbsp;approach&nbsp;may be slow during prediction and sensitive to the choice of k and the distance metric.<sup>22</sup></p>\r\n<p><strong><em>Performance evaluation metrics</em></strong></p>\r\n<p>The performance of the classification models was evaluated using accuracy, AUC, recall, precision, and F1. Accuracy measures the proportion of correctly classified instances among all observations and is defined as follows:</p>\r\n<p>where, TP, TN, FP, and FN represent true positive, true negative, false positive, and false negative values, respectively.</p>\r\n<p>Recall or sensitivity quantifies the model&rsquo;s capacity to identify actual positive instances and is calculated as follows:</p>\r\n<p>Precision indicates the proportion of true positive predictions among all positive predictions.</p>\r\n<p>The F1-score is the harmonic mean of Precision and Recall, serving as a single metric that balances the trade-off between them.</p>\r\n<p>AUC is the probability that a randomly selected positive observation is ranked higher by the model than a randomly selected negative observation. A higher AUC reflects a better ability to distinguish between classes.</p>\r\n<p><strong><em>Statistical analysis</em></strong></p>\r\n<p>Normality of quantitative variables was tested with the Kolmogorov-Smirnov test. An independent samples <em>t </em>- test was implemented to compare continuous variables between low and normal bone densities, and the data were expressed as the mean &plusmn; SD. Categorical variables were shown as n&nbsp;(%) and compared using the Pearson &chi;&sup2; test (or Fisher&rsquo;s exact test when expected counts were &lt; 5). All tests were two-tailed, with <em>p</em> &lt; 0.05 considered to indicate statistical significance. Analyses were performed in R version 4.3.2 (R Foundation for Statistical Computing, Vienna, Austria).</p>\r\n<p>ML models were conducted utilizing Python (version 3.10.0) within the JupyterLab environment (version 4.3.5). Data preprocessing, feature selection, model training, and evaluation were implemented with the PyCaret (version 3.2.0) library, an open-source, low-code ML framework that provides an integrated pipeline for classification and regression tasks. Performance evaluation metrics, such as accuracy, AUC, precision, recall, and F1, were computed to assess and compare the model performance.</p>\r\n<h3>RESULTS</h3>\r\n<p>A total of 12,108 individuals (female, 48%) who were &ge; 50 years of age (64 &plusmn; 9) and had complete femoral neck and total femur BMD data were included in this study. Approximately 45% of the participants were included in the low BMD group. The ML models were constructed employing 57 features, systematically categorized into seven categories to reflect their physiological and clinical relevance, as follows: 34 biochemical markers (including serum and urinary analytes), 12 hematological indices (components of the complete blood count), 4 demographic characteristics (age, sex, race/ethnicity, and income), 3 vital signs (pulse and blood pressure measurements), 2 self-reported clinical indicators (diabetes status and sleep duration), 1 anthropometric parameter (BMI), and 1 measure of physical function (walking ability).</p>\r\n<p><a href=\"javascript:openWin('uploads/grafik/table_BMJ_2788_0.jpg', 640, 480)\"><b>Table 1</b></a> summarizes the performance of the 11 ML classifiers in predicting low BMD. Models were ranked by accuracy. The ET achieved the best overall performance with an accuracy of 0.7672, AUC = 0.8524, recall = 0.6873, and precision = 0.7722. The RF followed closely (accuracy = 0.7621; AUC = 0.8446). LightGBM also performed well (AUC = 0.8104; precision = 0.7329), reflecting a balanced trade-off between sensitivity and specificity. Ensemble methods such as Gradient Boosting and AdaBoost showed moderate predictive performance, whereas linear models (e.g., LR, RC) yielded slightly lower accuracy but demonstrated consistent recall and AUC values. Hyperparameter tuning of the ET model using grid search with 10-fold cross-validation did not yield improvements; thus, the default configuration was retained for the final model. The key parameters included:<br />n_estimators = 100, criterion = &ldquo;gini&rdquo;, max_features = &ldquo;sqrt&rdquo;, min_samples_split = 2, min_samples_leaf = 1, and bootstrap = False. Other parameters were left at their default values, including max_depth = None, max_leaf_nodes = None, and random_state = 123 for reproducibility. The calibration of the best-performing model, the ET, was assessed to evaluate the reliability of its probability predictions. The calibration curve, as presented in <a href=\"javascript:openWin('uploads/grafik/figure_BMJ_2788_1.jpg', 640, 480)\"><b>Figure 2a</b></a>, demonstrated that the model was well-calibrated, as the plot of its predicted probabilities closely tracks the diagonal line representing perfect calibration. This visual finding is further supported by a low Brier score of 0.12, indicating a high degree of agreement between the predicted risks and the observed outcomes. In addition, the confusion matrix indicates the model achieved a sensitivity of 69% for detecting low BMD and a specificity of 84% for identifying normal BMD (<a href=\"javascript:openWin('uploads/grafik/figure_BMJ_2788_1.jpg', 640, 480)\"><b>Figure 2b</b></a>).</p>\r\n<p>After identifying the best-performing model, we conducted feature selection to determine the most influential risk factors implicated in low BMD. The result obtained from the recursive feature elimination with cross-validation approach utilizing the ET was presented in <a href=\"javascript:openWin('uploads/grafik/figure_BMJ_2788_2.jpg', 640, 480)\"><b>Figure 3</b></a>. The model&rsquo;s performance, as measured based on the cross-validated accuracy, increased with the addition of more features and then reached a plateau at approximately 14 features, with 0.767 accuracy. It demonstrates that a smaller, selected subset of variables can achieve strong predictive performance without including all available features.</p>\r\n<p>Using SHAP (SHapley Additive exPlanations) method, we identified 14 key predictors, including sex, age, BMI, race, family income/poverty, serum uric acid (mg/dL), diabetes status, HDL‑cholesterol (mg/dL), urinary creatinine (mg/dL), alkaline phosphatase (ALP; IU/L), mean cell volume (fL), lymphocyte (%), diastolic blood pressure (mmHg), and glycohemoglobin (%), and reported that this subset of features yielded the highest predictive accuracy for predicting low BMD. The comparison of the relevant variables between the low and normal BMD groups is presented in Table 2.</p>\r\n<p>The SHAP beeswarm plot illustrates both the importance and direction of each feature&rsquo;s impact on the model. The red points represent higher feature values, whereas the blue points indicate lower values. The x-axis reflects each feature&rsquo;s contribution to the model&rsquo;s prediction of low BMD. The top-ranked feature in the plot is the most influential in the prediction. Accordingly, sex, age, and BMI are the top three contributors to the model&rsquo;s prediction of low BMD. Female sex, older age, and having a lower BMI were found to be associated with a higher predicted risk of low BMD. In addition, demographic factors, race/ethnicity, and family income/poverty contributed meaningfully. Among the biochemical markers tested, lower uric acid levels were associated with increased predicted risk, whereas higher HDL-cholesterol levels were linked to higher risk (<a href=\"javascript:openWin('uploads/grafik/figure_BMJ_2788_3.jpg', 640, 480)\"><b>Figure 4a</b></a>). The SHAP bar plot displays the average absolute impact of each feature on the model&rsquo;s predictions (<a href=\"javascript:openWin('uploads/grafik/figure_BMJ_2788_3.jpg', 640, 480)\"><b>Figure 4b</b></a>). <a href=\"javascript:openWin('uploads/grafik/figure_BMJ_2788_3.jpg', 640, 480)\"><b>Figure 4c</b></a> presents the SHAP heatmap for the test set, wherein each column represents an individual, ordered left to right by the total magnitude of the SHAP values. In this figure, rows correspond to the most influential features. Red color reflects a risk-increasing contribution to the predicted probability of low BMD, whereas blue color is associated with a decreased risk. The black trace above the heat map [f(x)] shows the model&rsquo;s predicted risk per individual, confirming that columns with the largest cumulative pink area correspond to the highest predicted risk. Accordingly, the plot demonstrated that female sex, older age, and having a lower BMI were the strongest predictors of high-risk outcomes, consistently elevating the predicted values. Variables such as race, uric acid level, and HDL cholesterol exhibited mixed effects depending on the individual profiles. The participants with a lower income tended to cluster in higher-risk regions.</p>\r\n<p><a href=\"javascript:openWin('uploads/grafik/figure_BMJ_2788_4.jpg', 640, 480)\"><b>Figure 5</b></a> demonstrates the model-derived influence of the 10 most important predictors on low BMD risk, visualized as SHAP-dependence plots with LOWESS smoothing. The levels of uric acid, BMI, and urinary creatinine demonstrated negative correlations; higher levels of all three were associated with a lower predicted risk of low BMD, particularly up to approximately 8 mg/dL for uric acid, 35 kg/m&sup2; for BMI, and 150 mg/dL for urinary creatinine. These relationships appear to plateau beyond these thresholds, suggesting a potential nonlinear or saturation effect in the model&rsquo;s predictions. The predicted risk of low BMD displayed an inverse relationship with the diabetes status. As shown in the SHAP-dependence plot, individuals with diagnosed diabetes (coded 2) had the lowest predicted risk of low BMD, followed by those with prediabetes (coded 1), compared with individuals without diabetes (coded 0). Non-Hispanic White individuals (3 coded) were most strongly associated with increased and predicted risk of low BMD, making them the highest-risk ethnic category. The family income-to-poverty ratio showed an inverse relationship with predicted low BMD risk. In other words, a higher ratio was linked to a lower predicted risk. Higher HDL cholesterol and ALP levels were both associated with an increased predicted risk of low BMD.</p>\r\n<p><a href=\"javascript:openWin('uploads/grafik/figure_BMJ_2788_5.jpg', 640, 480)\"><b>Figure 6</b></a> shows sex-stratified SHAP importance profiles. In both graphs, age and BMI acted as the primary influencing factors, albeit the magnitude of their effects differed. For instance, higher BMI was associated with a greater reduction in the predicted risk in women (SHAP range: -0.30 to  0.00) compared to men (-0.15 to  0.00). In addition to the similar predictors, sex-specific differences were recorded among other influential features in the top 10, with urinary creatinine and ALP levels having a greater impact in men, whereas the serum globulin and C-reactive protein (CRP) levels were more influential in women.</p>\r\n<h3>DISCUSSION</h3>\r\n<p>In this study, we applied ML approaches to predict low BMD using demographic, clinical, and biochemical data from the NHANES dataset. Among eleven classifiers, ensemble tree-based models, particularly the ET, highlights the capability of ML to capture complex, nonlinear interactions. Similar findings have been reported in previous studies, where tree-based ML algorithms, such as Random Forest, XGBoost, and LightGBM, achieved superior performance in predicting osteoporosis or low BMD risk.<sup>23-25</sup> The Extra Trees algorithm has also exhibited strong predictive accuracy in other biomedical domains, including coronary artery disease, Hodgkin lymphoma, Parkinson&rsquo;s disease, cervical cancer, and <em>Helicobacter pylori.</em> These results emphasize its robustness and adaptability across complex and diverse patterns and datasets.<sup>26-30</sup></p>\r\n<p>Our findings reaffirmed well-established predictors such as age, sex, and BMI, which consistently show strong associations with osteoporosis risk.<sup>31,32</sup> Older age, female sex, and lower BMI were significantly associated with reduced BMD, consistent with prior evidence linking age-related bone loss and postmenopausal hormonal decline to reduced bone mass.<sup>31-33</sup></p>\r\n<p>Although univariate analyses (<a href=\"javascript:openWin('uploads/grafik/table_BMJ_2788_1.jpg', 640, 480)\"><b>Table 2</b></a>) revealed statistically significant differences for all variables, such results must be interpreted cautiously, given the large sample size, where small absolute differences may appear significant. For instance, variations in family income/poverty or lymphocyte percentage may hold limited clinical importance individually. However, this finding highlights the strength and rationale of the ML approach. Notably, the variables presented in <a href=\"javascript:openWin('uploads/grafik/table_BMJ_2788_1.jpg', 640, 480)\"><b>Table 2</b></a> were identified through SHAP values as the top contributors in the ML models. Unlike the marginal comparisons shown in <a href=\"javascript:openWin('uploads/grafik/table_BMJ_2788_1.jpg', 640, 480)\"><b>Table 2</b></a>, the SHAP values quantify the conditional contribution of each feature, considering the interactions with all other predictors in the model. Consequently, a variable exhibited a small univariate effect, but continued to play a crucial role in the model&rsquo;s predictive power owing to its cumulative and interactive effects. This dual perspective emphasized the necessity of integrating traditional statistical comparisons with ML-based feature importance for a comprehensive interpretation of the predictors of low BMD.</p>\r\n<p>Beyond conventional risk factors, SHAP analysis revealed additional, biologically plausible contributors. The present study&rsquo;s results align with the latest population‑based analysis demonstrating an inverse (non‑linear) association between the serum uric acid levels and BMD among Chinese and American cohorts, suggesting that higher uric acid may offer a protective effect on the bone mass up to a threshold level.<sup>34</sup> Considering the damaging consequences of oxidative stress on bone metabolism, the antioxidant properties of uric acid may represent a potential protective mechanism against low BMD.<sup>35</sup> Although HDL cholesterol is regarded as a protective factor in the context of cardiovascular diseases, recent studies have suggested that high HDL levels may be associated with an increased risk of osteoporosis.<sup>36</sup> Preclinical studies have indicated that HDL leads to reduced BMD by adversely affecting the osteoblast number and function.<sup>37</sup> Consistent with these findings, our study recorded that higher HDL levels, particularly above 65-70 mg/dL, were associated with a higher predicted risk of low BMD. Despite diabetes appearing as a risk factor in the low BMD group, the SHAP values exhibited an overall positive influence, indicating a higher BMD among diabetic individuals. This finding is consistent with those of several studies, particularly in relation to type-2 diabetes that report normal or even higher BMD values.<sup>38,39</sup> In addition, glycohemoglobin level reflects the average level of glucose in the blood over the past 2-3 months, and it serves to diagnose prediabetes. Similarly, our findings indicated that higher glycohemoglobin levels were inversely associated with lower BMD, as has been documented across several previous studies.<sup>40,41</sup></p>\r\n<p>Another notable finding was a positive association between urinary creatinine and BMD, which has most commonly been explored through ratio-based indices, such as urinary calcium/creatinine or ALP/creatinine, with emerging evidence supporting a direct association. For instance, Kim et al.<sup>42</sup> reported that, in patients with chronic kidney disease, higher urinary creatinine levels were positively correlated with BMD, implying that urinary creatinine could indicate maintained muscle mass and metabolic health, both of which are beneficial for skeletal integrity. Similarly, Schwaderer et al.<sup>43</sup> reported that children with low BMD exhibited significantly lower urinary creatinine levels. These findings are consistent with our results that identified urinary creatinine as a positive predictor of BMD, particularly in men, highlighting its potential utility as a noninvasive marker in osteoporosis risk assessment.</p>\r\n<p>ALP displayed a nonlinear association with BMD, where levels up to 130 U/L correlated with sharp declines in BMD, followed by a plateau. This pattern is consistent with findings from Cheng and Zhao<sup>44</sup>, who reported similar nonlinearity between ALP and BMD using generalized additive models. However, in our sex-stratified analysis, ALP ranked higher among males, whereas its impact in females was relatively weaker, likely due to the dominance of hormonal and inflammatory factors.</p>\r\n<p>Socioeconomic status, as quantified by the family income/poverty, demonstrated an inverse association with a low BMD risk, which is consistent with past reports linking lower income to poorer bone health outcomes as a result of reduced access to nutrition, healthcare, and physical activity.<sup>45</sup> The presence of such a gradient highlights the importance of incorporating social determinants into predictive modeling for osteoporosis. Similarly, racial and ethnic backgrounds have emerged as influential factors, reflecting disparities in bone health potentially stemming from genetic differences, cultural behaviors, or unequal access to healthcare resources.<sup>46</sup></p>\r\n<p>Sex-specific analyses revealed that age and BMI remained the strongest predictors in men and women, though the protective effect of BMI was more pronounced in men, while age exerted a stronger influence in women. Urinary creatinine and ALP ranked higher among men, whereas globulin and CRP were stronger predictors among women. Elevated CRP, a marker of inflammation, has been widely associated with lower BMD, particularly in women,<sup>48</sup> while globulin-related measures (e.g., albumin-to-globulin ratio) may reflect nutritional and inflammatory status relevant to osteoporosis risk.<sup>47 </sup>Despite its strength, this study has several limitations. The cross-sectional design of NHANES restricts causal inference. Key variables such as genetic data, menopausal status, and physical activity were excluded due to missing data. Although SHAP values enhance interpretability, the biological implications of some nonlinear relationships warrant further investigation. Additionally, our analyses were conducted on an unweighted NHANES sample, and external validation in independent populations would strengthen generalizability. Nonetheless, the primary goal, to compare ML algorithms and identify influential predictors, was effectively achieved.</p>\r\n<p>In conclusion, this study demonstrates the feasibility and interpretability of ML-based models, particularly tree-based algorithms, for accurate prediction of low BMD using routinely collected health data. The ET showed the highest predictive performance. By integrating SHAP-based interpretability, we uncovered biologically and socioeconomically meaningful predictors that could inform personalized screening strategies and public health interventions aimed at reducing the burden of osteoporosis and osteopenia.</p>\r\n<p><strong>Ethics Committee Approval:</strong> Not applicable.</p>\r\n<p><strong>Informed Consent:</strong> Not applicable.</p>\r\n<p><strong>Data Sharing Statement:</strong> The data that support the findings of this study are available from the corresponding author upon reasonable request.</p>\r\n<p><strong>Authorship Contributions:</strong> Concept- E.K., S.K.; Design- E.K., S.K.; Supervision- S.K.; Materials- E.K., Data Collection or Processing- E.K.; Analysis or Interpretation- E.K.; Literature Review- E.K., S.K.; Writing- E.K., S.K.; Critical Review- E.K., S.K.</p>\r\n<p><strong>Conflict of Interest:</strong> The authors declare that they have no conflict of interest.</p>\r\n<p><strong>Funding:</strong> The authors declared that this study received no financial support.</p>\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t<!--\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t<div\tstyle=\"width:20%; float:left; min-height:150px; padding:10px; padding-top:40px;\">\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t\t\t\t<a class=\"menu\" href=\"#summary_en\">Summary</a><a class=\"selected_menu\" href=\"#introduction\">Introduction</a><a class=\"menu\" href=\"#reference\">Reference</a>\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t-->\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t<div  style=\"width:100%; float:left;  padding-bottom:0px;\">\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t<div\tstyle=\"width:100%; float:left; min-height:45px; text-align:justify\">\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t<a href=\"\" name=\"reference\"></a>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t<!--<h2>Reference</h2>-->\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t<h3>REFERENCES</h3>\r\n<ol>\r\n<li>Kanis JA. Assessment of fracture risk and its application to screening for postmenopausal osteoporosis: synopsis of a WHO report. WHO study group. <em>Osteoporos Int.</em> 1994;4:368-381.</li>\r\n<li>Cotts KG, Cifu AS. Treatment of osteoporosis. 2018;319:1040-1041.</li>\r\n<li>Lisk R, Yeong K. Reducing mortality from hip fractures: a systematic quality improvement programme. <em>BMJ Qual Improv Rep.</em> 2014;3:u205006.w2103.</li>\r\n<li>Adler RA. Osteoporosis in men: a review. <em>Bone Res.</em> 2014;2:14001.</li>\r\n<li>Si Z, Zhang D, Wang H, Zheng X. PrOsteoporosis: predicting osteoporosis risk using NHANES data and machine learning approach. <em>BMC Res Notes.</em> 2025;18(1):108.</li>\r\n<li>Xu R, Chen Y, Yao Z, et al. Application of machine learning algorithms to identify people with low bone density. <em>Front Public Health.</em> 2024;12:1347219.</li>\r\n<li>Nabavi A, Safari F, Faramarzi A, et al. Machine learning analysis of cardiovascular risk factors and their associations with hearing loss. <em>Sci Rep.</em> 2025;15(1):9944.</li>\r\n<li>Guo K, Ni W, Du L, Zhou Y, Cheng L, Zhou H. Environmental chemical exposures and a machine learning-based model for predicting hypertension in NHANES 2003-2016. <em>BMC Cardiovasc Disord.</em> 2024;24(1):544.</li>\r\n<li>Liu Y, Li K, Zhang Y, et al. Impact of phthalate exposure and blood lipids on breast cancer risk: machine learning prediction. <em>Environ Sci Eur.</em> 2025;37:39.</li>\r\n<li>Hinton BJ, Fan B, Ng BK, Shepherd JA. Dual energy X-ray absorptiometry body composition reference values of limbs and trunk from NHANES 1999-2004 with additional visualization methods. <em>PLoS One.</em> 2017;12:e0174180.</li>\r\n<li>Looker AC, Wahner HW, Dunn WL, et al. Updated data on proximal femur bone mineral levels of US adults. <em>Osteoporos Int.</em> 1998;8(5):468-489.</li>\r\n<li>Zoppi T, Gazzini S, Ceccarelli A. Anomaly-based error and intrusion detection in tabular data: no DNN outperforms tree-based classifiers. <em>Future Generation Computer Systems.</em> 2024;160:951&ndash;965.</li>\r\n<li>Nakagomi A, Kondo K, Shiba K. Heterogeneity in the association between internet use and dementia among older adults: a machine-learning analysis. <em>Arch Gerontol Geriatr</em>. 2025;136:105912.</li>\r\n<li>Sai MJ, Chettri P, Panigrahi R, Garg A, Bhoi AK, Barsocchi P. An ensemble of light gradient boosting machine and adaptive boosting for prediction of type-2 diabetes. <em>Int J Comput Intell Syst.</em> 2023;16:14.</li>\r\n<li>J M SL, P S. Unveiling the potential of machine learning approaches in predicting the emergence of stroke at its onset: a predicting framework<em>. Sci Rep.</em> 2024;14(1):20053.</li>\r\n<li>Anghele AD, Marina V, Dragomir L, Moscu CA, Anghele M, Anghel C. Predicting deep venous thrombosis using artificial ıntelligence: a clinical data approach. <em>Bioengineering (Basel).</em> 2024;11:1067.</li>\r\n<li>Zhao S, Zhang B, Yang J, Zhou J, Xu Y. Linear discriminant analysis. <em>Nat Rev Methods Primers.</em> 2024;4.</li>\r\n<li>Li N, Peng E, Liu F. Prediction of lymph node metastasis in cervical cancer patients using AdaBoost machine learning model: analysis of risk factors. <em>Am J Cancer Res.</em> 2025;15:1158-1173.</li>\r\n<li>Peng C, Cheng Q. Discriminative Ridge Machine: A Classifier for High-Dimensional Data or Imbalanced Data. <em>IEEE Trans Neural Netw Learn Syst.</em> 2021;32:2595-2609.</li>\r\n<li>Du KL, Jiang B, Lu J, Hua J, Swamy MNS. Exploring kernel machines and support vector machines: principles, techniques, and future directions<em>. Mathematics</em>. 2024;12:3935.</li>\r\n<li>Hou R, Wang X, Zhang W, et al. Decision tree extraction for clinical decision support system with ıf-else pseudocode and planselect strategy. <em>IEEE J Biomed Health Inform.</em> 2025;29:3642-3653.</li>\r\n<li>Boddu AS, Jan A. A systematic review of machine learning algorithms for breast cancer detection. <em>Tissue Cell</em>. 2025;95:102929.</li>\r\n<li>He W, Chen S, Fu X, Xu L, Xie J, Wan J. Development and evaluation of interpretable machine learning regressors for predicting femoral neck bone mineral density in elderly men using NHANES data. <em>Biomol Biomed.</em> 2025;25:375-390.</li>\r\n<li>Jin W, Xu L, Yue C, et al. Development and validation of explainable machine learning models for female hip osteoporosis using electronic health records<em>. Int J Med Inform. </em>2025;199:105889.</li>\r\n<li>Shi H, Fang Y, Ma X. Application of machine learning algorithms in osteoporosis analysis based on cardiovascular health assessed by life&rsquo;s essential 8: a cross-sectional study. <em>J Health Popul Nutr</em>. 2025;44:180.</li>\r\n<li>Lyu Y, Wu HM, Yan HX, et al. Classification of coronary artery disease using radial artery pulse wave analysis via machine learning. <em>BMC Med Inform Decis Mak. </em>2024;24:256.</li>\r\n<li>Albano D, Cuocolo R, Patti C, et al. Whole-body MRI radiomics model to predict relapsed/refractory Hodgkin Lymphoma: a preliminary study. <em>Magn Reson Imaging. </em>2022;86:55-60.</li>\r\n<li>Rojas-Velazquez D, Kidwai S, Liu TC, et al. Understanding Parkinson&rsquo;s: the microbiome and machine learning approach. 2025;193:108185.</li>\r\n<li>Wang Q, Liang T, Li Y, Zhou P, Liu X. Machine learning for prediction of Helicobacter pylori infection based on basic health examination data in adults: a retrospective study. <em>Front Med (Lausanne).</em> 2025;12:1587540.</li>\r\n<li>Arage FG, Tadese ZB, Taye EA, Tsegaw TK, Abate TG, Alemu EA. Cervical cancer screening uptake and its associated factor in Sub-Sharan Africa: a machine learning approach. BMC Med <em>Inform Decis Mak. </em>2025;25:197.</li>\r\n<li>Wang J, Shu B, Tang DZ, et al. The prevalence of osteoporosis in China, a community based cohort study of osteoporosis. <em>Front Public Health. </em>2023;11:1084005.</li>\r\n<li>Pi&ntilde;ar-Gutierrez A, Garc&iacute;a-Fontana C, Garc&iacute;a-Fontana B, Mu&ntilde;oz-Torres M. Obesity and Bone Health: A Complex Relationship. <em>Int J Mol Sci. </em>2022;23:8303.</li>\r\n<li>Kanto A, Kotani Y, Murakami K, et al. Risk factors for future osteoporosis in perimenopausal Japanese women<em>. Menopause. </em>2022;29:1176-1183.</li>\r\n<li>Li X, Peng Y, Chen K, Zhou Y, Luo W. Association between serum uric acid levels and bone mineral density in Chinese and American: a cross-sectional study. <em>Sci Rep</em>. 2025;15:8304.</li>\r\n<li>Kimball JS, Johnson JP, Carlson DA. Oxidative stress and osteoporosis. <em>J Bone Joint Surg Am</em>. 2021;103:1451-1461.</li>\r\n<li>Tang Y, Wang S, Yi Q, Xia Y, Geng B. High-density lipoprotein cholesterol ıs negatively correlated with bone mineral density and has potential predictive value for bone loss. <em>Lipids Health Dis</em>. 2021;20:75.</li>\r\n<li>Hussain SM, Ebeling PR, Barker AL, Beilin LJ, Tonkin AM, McNeil JJ. Association of plasma high-density lipoprotein cholesterol level with risk of fractures in healthy older adults. <em>JAMA Cardiol. </em>2023;8:268-272.</li>\r\n<li>Zoulakis M, Johansson L, Litsne H, Axelsson K, Lorentzon M. Type 2 diabetes and fracture risk in older women<em>. JAMA Netw Open.</em> 2024;7:e2425106.</li>\r\n<li>Oei L, Zillikens MC, Dehghan A, et al. High bone mineral density and fracture risk in type 2 diabetes as skeletal complications of inadequate glucose control: the Rotterdam Study. <em>Diabetes Care</em>. 2013;36:1619-1628.</li>\r\n<li>Ji X, Hong J, Qu Z, et al. HemoglobinA1c ıs a risk factor for changes of bone mineral density: a mendelian randomization study. <em>Front Endocrinol (Lausanne). </em>2022;13:942878.</li>\r\n<li>Gao L, Liu Y, Li M, Wang Y, Zhang W. Based on HbA1c analysis: bone mineral density and osteoporosis risk in postmenopausal female with T2DM<em>. J Clin Densitom. </em>2024;27:101442.</li>\r\n<li>Kim SE, Jung SH, Yang J, et al. Association between urine creatinine excretion and bone mineral density in chronic kidney disease: Results from the KNOW-CKD study. <em>J Nephrol. </em>2024;38:189&ndash;196.</li>\r\n<li>Schwaderer AL, Cronin R, Mahan JD, Bates CM. Low bone density in children with hypercalciuria and/or nephrolithiasis. <em>Pediatr Nephrol. </em>2008;23:2209-2214.</li>\r\n<li>Cheng X, Zhao C. The correlation between serum levels of alkaline phosphatase and bone mineral density in adults aged 20 to 59 years. <em>Medicine (Baltimore). </em>2023;102:e34755.</li>\r\n<li>Gough Courtney M, Roberts J, Godde K. Structural ınequity and socioeconomic status link to osteoporosis diagnosis in a population-based cohort of middle-older-age Americans. 2023;60:469580231155719.</li>\r\n<li>Noel SE, Santos MP, Wright NC. Racial and ethnic disparities in bone health and outcomes in the United States. <em>J Bone Miner Res. </em>2021;36:1881-1905.</li>\r\n<li>Yan H, Yang J, Dai Y, Li Y, Zhang P, Li L. The association between the albumin to globulin ratio and thoracic spine bone mineral density in adolescents: NHANES 2011-2016. <em>Front Nutr. </em>2025;12:1560013.</li>\r\n<li>Ilesanmi-Oyelere BL, Schollum L, Kuhn-Sherlock B, et al. Inflammatory markers and bone health in postmenopausal women: a cross-sectional overview. <em>Immun Ageing. </em>2019;16:15.</li>\r\n</ol>\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t<!--\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t<div\tstyle=\"width:20%; float:left; min-height:150px; padding:10px; padding-top:40px;\">\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t\t\t\t<a class=\"menu\" href=\"#summary_en\">Summary</a><a class=\"menu\" href=\"#introduction\">Introduction</a><a class=\"selected_menu\" href=\"#reference\">Reference</a>\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t-->\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t        \t\t\t\n\t\t\n\t\t\t\t\t\t\t\t\t\t\t        \t</div>";
